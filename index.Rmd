---
title: "Sign Language Recognizer"
author: "Arya"
date: '`r Sys.Date()`'
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    theme: flatly
    highlight: zenburn
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(keras)
library(dplyr)
library(caret)
library(readr)
```

Kali ini, kita akan membuat _Sign Language recognizer_ menggunakan metode _Machine Learning_ bernama Neural Network. 

Kita akan menggunakan dataset MNIST, yakni data berisi ribuan gambar bahasa isyarat atau _Sign Language_ dari berbagai jenis tangan. Kita akan membuat sebuah model Machine Learning yang nantinya dapat mengenali bahasa isyarat dari A sampai Z dengan belajar dari informasi yang diberikan.

# Import Data

```{r}
sign <- read.csv("data/sign_mnist_train.csv")
```

# Exploratory Data Analytics (EDA)

```{r}
head(sign)[,1:9]
```

```{r}
dim(sign)
```


Dari data diatas, bisa dilihat total column berjumlah sebanyak 785. Yang terdiri dari satu label dan 784 pixel atau gambar (28x28).

Pada kolom label diatas terdiri dari 0-25, yang memiliki arti

0 = A  
1 = B  
2 = C  
3 = D  
4 = E  
5 = F  
6 = G  
7 = H  
8 = I  
9 = J  
10 = K  
11 = L  
12 = M  
13 = N  
14 = O  
15 = P  
16 = Q  
17 = R  
18 = S  
19 = T  
20 = U  
21 = V  
22 = W  
23 = X  
24 = Y  
25 = Z  

Karena `label` target terdiri dari angka, mari kita buat kamus untuk mengubahnya menjadi arti sebenarnya yaitu Huruf A-Z.

```{r}
label_mapping <- c(
  "0" = "A",
  "1" = "B",
  "2" = "C",
  "3" = "D",
  "4" = "E",
  "5" = "F",
  "6" = "G",
  "7" = "H",
  "8" = "I",
  "9" = "J",
  "10" = "K",
  "11" = "L",
  "12" = "M",
  "13" = "N",
  "14" = "O",
  "15" = "P",
  "16" = "Q",
  "17" = "R",
  "18" = "S",
  "19" = "T",
  "20" = "U",
  "21" = "V",
  "22" = "W",
  "23" = "X",
  "24" = "Y",
  "25" = "Z"
)
```

```{r, include=FALSE}
vizTrain <- function(input){
  
  dimmax <- sqrt(ncol(input[,-1]))
  
  dimn <- ceiling(sqrt(nrow(input)))
  par(mfrow=c(dimn, dimn), mar=c(.1, .1, .1, .1))
  
  for (i in 1:nrow(input)){
      m1 <- as.matrix(input[i,2:785])
      dim(m1) <- c(28,28)
      
      m1 <- apply(apply(m1, 1, rev), 1, t)
      
      image(1:28, 1:28, 
            m1, col=grey.colors(255), 
            # remove axis text
            xaxt = 'n', yaxt = 'n')
      text(2, 20, col="black", cex=1.2, input[i, 1])
  }
}
```

Jika divisualisasikan data kita akan berbentuk seperti berikut.

```{r}
vizTrain(
  sign %>% 
    head(9) %>% 
    mutate(
      label = label_mapping[as.character(label)] %>% 
        as.vector()
    )
)
```

# Data Preprocessing

## Data labeling

Target pada data dilabel menggunakan angka, agar mempermudah untuk menginterpretasi dan membaca hasil prediksi. Marilah kita melabel data target.

```{r}
sign <- sign %>% 
  mutate(
    label_char = label_mapping[as.character(label)] %>% 
      as.vector() %>% 
      as.factor()
  )
```

```{r}
sign %>% 
  head() %>% 
  select(label, label_char)
```

## Check data distribution

```{r}
prop.table(table(sign$label_char))
```

Jika dilihat dari distribusi data target, proporsi per category sekitar 0.4 yang berarti cukup seimbang.

## Cross validation

Selanjutnya kita akan membagi data kita menjadi 80% data _train_ dan 20% data _test_.

```{r}
set.seed(123)
idx <- sample(nrow(sign), nrow(sign)*0.8)
sign.train <- sign[idx,]
sign.test <- sign[-idx,]
```

## Data preperation

Sebelum membuat model, ada beberapa hal yang perlu dilakukan untuk mempersiapkan data:

1. Memisahkan prediktor dengan target variabel
2. Mengubah prediktor menjadi matrix/array
3. Melakukan one-hot encoding apabila target variabel adalah kategori

Karena prediktornya adalah nilai kecerahan dari tiap pixel, kita tahu bahwa range nilainya bisa antara 0 hingga 255. Setiap pixel akan di-scaling dengan membagi nilai pixel terhadap 255. Setelah di-scaling, tiap kolom prediktor akan memiliki range antara 0-1.

```{r}
target <- c("label", "label_char")
```

```{r}
sign.train.x.keras <- sign.train %>% 
  select(-target) %>%
  as.matrix() / 255
sign.train.x.keras <- array_reshape(
  x=sign.train.x.keras,
  dim = dim(sign.train.x.keras)
)
sign.test.x.keras <- sign.test %>% 
  select(-target) %>% 
  as.matrix() / 255
sign.test.x.keras <- array_reshape(
  x=sign.test.x.keras,
  dim = dim(sign.test.x.keras)
)

sign.train.y.keras <- sign.train$label
sign.test.y.keras <- sign.test %>% 
  select(label, label_char)

sign.train.y.keras <- to_categorical(
  y=sign.train.y.keras,
  num_classes=dim(sign.train.y.keras)
)
```

# Build Model

## Create Neural Network Architecture

Langkah selanjutnya adalah membangun arsitektur Neural Network. Beberapa ketentuan ketika membuat arsitektur Neural Network:

1. Selalu diawali `keras_model_sequential()`
2. Layer pertama yang dibuat akan menjadi hidden layer pertama
3. Input layer dibuat dengan memasukkan parameter `input_shape` pada layer pertama
4. Layer terakhir yang dibuat akan menjadi output layer

```{r}
tensorflow::tf$random$set_seed(123)

inputshape <- ncol(sign.train.x.keras)
outputshape <- ncol(sign.train.y.keras)

model <- keras_model_sequential(name="model-sign") %>% 
  layer_dense(
    units=128,
    input_shape = inputshape,
    activation = "relu",
    name="hidden-1"
  ) %>%
  layer_dense(
    units=64,
    activation = "relu",
    name="hidden-2"
  ) %>% 
  layer_dense(
    units=32,
    activation = "relu",
    name="hidden-3"
  ) %>% 
  layer_dense(
    units=16,
    activation = "relu",
    name="hidden-4"
  ) %>% 
  layer_dense(
    units=outputshape,
    activation = "softmax",
    name="output-1"
  )
```

## Compile model

Langkah berikutnya adalah menentukan error function, optimizer, dan metrics yang akan ditunjukkan selama training.

Kita akan menggunakan
loss = `categorical_crossentropy`
optimizer = `adam`
learning rate = `0.001`
metrics = `accuracy`

```{r}
model %>% 
  compile(
    loss = "categorical_crossentropy",
    optimizer=optimizer_adam(lr=0.001),
    metrics="accuracy"
  )
```

## Train model

Dan tidak kalah penting, kita harus melatih model dengan data train yang telah dipersiapkan.
Model kita akan ditrain menggunakan `epochs` sebesar `15`, `batch_size` sebesar `32` dan `validation_split` sebesar `0.1`

```
hist <- model %>% 
  fit(
    x=sign.train.x.keras,
    y=sign.train.y.keras,
    epochs=15,
    batch_size=16,
    validation_split=0.1
  )

saveRDS(hist, "model.RDS")
```

```{r}
hist <- readRDS("model.RDS")

plot(hist)
```

# Validate Model

Setelah membuat model, langkah terakhir adalah memvalidasi modelnya.

## Predict

Pertama, marilah kita buat prediksi dari data test menggunakan model yang baru kita buat.

```{r}
result <- predict_classes(model, sign.test.x.keras)

result <- label_mapping[as.character(result)] %>% 
  as.vector() %>% 
  as.factor()
```

## Confusion Matrix

Selanjutnya marilah kita mengetest ke akurasi hasil prediksi data test kita menggunakan confusion matrix.

```{r}
confusionMatrix(result, sign.test.y.keras$label_char)
```

Jika dilihat dari confussion matrix diatas, model kita mendapat 0.9752 yang artinya mendapat akurasi sebesar 97.52% atau sangat akurat.

## False Prediciton

Berikut beberapa prediksi yang salah.

```{r, include=FALSE}
vizTest <- function(input){
  
  dimmax <- sqrt(ncol(input[,-1]))
  
  dimn <- ceiling(sqrt(nrow(input)))
  par(mfrow=c(dimn, dimn), mar=c(.1, .1, .1, .1))
  
  for (i in 1:nrow(input)){
      m1 <- as.matrix(input[i,2:785])
      dim(m1) <- c(28,28)
      
      m1 <- apply(apply(m1, 1, rev), 1, t)
      
      image(1:28, 1:28, 
            m1, col=grey.colors(255), 
            # remove axis text
            xaxt = 'n', yaxt = 'n')
      # text(2, 20, col="black", cex=1.2, input[i, 1])
      text(2, 20, col="blue", cex=1.2, input[i, 786])
      text(4, 20, col="red", cex=1.2, input[i, 787])
  }
}
```

```{r}
result.false <- sign.test %>% 
  mutate(
    label_pred = result,
  ) %>% 
  filter(as.character(label_pred) != as.character(label_char)) %>% 
  head(9)

vizTest(result.false)
```

# Conclusion

Dalam memprediksi bahasa isyarat, model _Neural Network_ sangatlah cocok. Dan mendapatkan akurasi sebesar 97.52%.
